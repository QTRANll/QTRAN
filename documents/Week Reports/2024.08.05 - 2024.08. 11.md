一句话总结

* 论文阅读，mutate llm的微调尝试和评估方法的学习，mutate llm思路完善和修改。

本周工作：
* 论文阅读：
	* Evaluating and Improving ChatGPT for Unit Test Generation
	* Mallet SQL Dialect Translation with LLM Rule Generation
* mutate llm的微调与微调模型的效果评估
	* 微调mysql的mutate llm：训练集100条数据+测试集111条数据
	* 效果评估：openai官方微调的评估+学习官方推荐的评估框架Eval
* mutate llm的思路补充和修正 


下周计划：
* pinolo的mutate llm实现：
	* 变异策略的范围：pinolo已经报出bug的八种变异策略
	* 变异db的范围：先为postgres的mutate进行微调
	* 微调训练集+测试数据集来源：修改transfer llm转换并可成功执行的postgres语句
	* 评估：openai微调评估+Eval







---

SQLancer的变异策略复杂，先不管
SQLancer：
* 变异策略：TLP,noREC
* DB：mysql(TLP),tidb(TLP),oceanbase(TLP,noREC),postgres(TLP,noREC),sqlite(TLP,noREC),cockroachdb(TLP,noREC)

---
* 有空也可以看看这篇论文，我觉得他的这个思路挺好的，就是没有公开源码：Mallet SQL Dialect Translation with LLM Rule Generation


1. 此想法效果不大，还是要用domin knowledge，具体原因见官网关于fine-tuning的说明，微调可以覆盖一些不存在feature对应关系的边缘情况（- **Handling many edge cases in specific ways**）。      微调替代few-shot（transfer llm）：few-shot对效果（尤其是对于执行结果一样的比例）有较好的提升（主要去尝试mariadb转postgres的），微调可以考虑作为边缘知识的补充
2. 对于长度过长的sql，可以考虑拆分执行，再合并！！

* mysql_like的ddl文件把insert语句都修改了一下（ok），重新把对应的数据表删除又建了一下（ok），后面应该要重新跑数据（还没重新跑mariadb to mysql）